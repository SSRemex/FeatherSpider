# 基于Puppeteer的深度爬虫

### 一  Puppeteer

Puppeteer 是一个 Node 库，它提供了一个高级 API 来通过 DevTools 协议控制 Chromium 或 Chrome。Puppeteer 默认以 headless 模式运行，但是可以通过修改配置文件运行“有头”模式。

相较于selenium，puppeteer有如下特点

- 更简单的javaScript执行
- 网络拦截
- 测试处理失败的请求
- 模拟第三方服务
- 测试离线模式
- 调试
- 单个浏览器，单一语言

**示例代码**

```js
const puppeteer = require('puppeteer');

(async () => {
  const browser = await puppeteer.launch();
  const page = await browser.newPage();
  await page.goto('https://example.com');
  await page.screenshot({path: 'example.png'});

  await browser.close();
})();
```



**异步操作**

JavaScript本身只有一个主线程，所有程序都在一个主线程中执行

在使用puppeteer时，会经常用到 `async`，`await`实现异步操作

`async`写在一个函数前，代表该函数是一个异步函数，此时才可以在该函数中使用`await`

值得一提的是，如上述代码当出些多个 `await`语句时，这些语句的执行会按照`await`的顺序依次执行，相当于当前`await`语句暂停了后续`await`语句



### 二 目录结构

>├── README.md
>├── config.js # 参数配置
>├── main.js # 主程序
>├── node_modules
>├── package-lock.json
>├── package.json # 依赖
>├── test.js # 测试程序

### 三 爬虫设计

#### url提取

整体爬虫的url提取分为三个模块进行

**ajax 模块**

```js
page.setRequestInterception(true);
page.on('request', ajax_get);
```

开启拦截之后，给page配置request操作，当有request行为产生时，便执行ajax_get()函数，并会 给它传入一个req参数

当执行完ajax_get()函数的内容后，此时该请求依旧被拦截没有放行，所以需要`req.continue()`让请求继续执行

可捕获`GET`，`POST`



**form模块**

```js
var f = document.forms; //获取当前页面所有的form

// 进行循环

var url = f[i].action; //获取 url
var inputs = f[i].getElementsByTagName('*'); // 获取该表单内的所有标签

// 对 inputs进行循环
// 找到如下元素属性 并进行格式化数据填充存储
inputs[j].hasAttributes("name")
inputs[j].hasAttributes("value")
```

可捕获`POST`

**href模块**

```js
var tag_dict = {'a': 'href','link': 'href','area': 'href','img': 'src','embed': 'src','video': 'src','audio': 'src'}

// 对当前页面按照上述字典进行标签循环提取
var elements = document.getElementsByTagName(tag);
```

可捕获`GET`



#### 布隆过滤去重

```js
const BloomFilter = require('bloomfilter.js');
```





#### 参数配置

```js
// 扫描域名 末尾不要加/
const ROOT_URL = "https://www.ntu.edu.tw";

// cookie 字符串
const Cookie_str = "";

// url最大超时时间（毫秒）
const TIMEOUT = 10000

// 是否开启无头
const IS_HEADLESS = true;
// 递归深度
const DEEP = 3;

// 黑白都为空时，代表不作限制
// 保留白域名 
// eg: ["baidu.com", "hao123.com"]
const WHITE_DOMAIN = ["edu.tw"]

// 过滤黑域名 
// 设置白域名不为空时，黑域名自动为空，二者只能同时支持一种
const BLACK_DOMAIN = []

// 是否只爬取 ROOT_URL的host
// 该值为true时 黑白域名失效
const HOST_LOCKED = true

// uri重复等级 1（不过滤重复，重复数极大） 2 3（完全不重复）默认建议为 2
const LEVEL = 2
```



#### 内置过滤器

```js
let black_list = ['.svg', '.png', '.js', '.jpg', '.ico', '.apk', '.exe', '.css', '.csv', '.js?', '.css?'];
```



#### 递归设计

![](D:\puppeteer文档\FeatherSpider\递归.png)

### 四  Rad对比

百度



台湾某大学



### 五 后续规划

* 已知BUG优化调研
* 黑白域名限制精确化
* 动态登录Cookie获取
* 点击事件调研
* 参数格式化脚本开发，供个人漏洞POC使用